{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV-YOLO workflow\n",
    "**image/images -> cv2.dnn.blobFromImage [pre-processing images] -> blob -> yolo -> output predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 412,
     "status": "ok",
     "timestamp": 1648044523037,
     "user": {
      "displayName": "lukman",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgYWpdLEDBgd-A_noCt6O-q-oYOLk5CEobYugF7pw=s64",
      "userId": "07982345385280399353"
     },
     "user_tz": -330
    },
    "id": "iDLcAk8PDUHd"
   },
   "outputs": [],
   "source": [
    "## importing important packages\n",
    "\n",
    "import cv2         # computer vision\n",
    "import numpy as np # for array structure computing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## showing an image\n",
    "\n",
    "img = cv2.imread('image3.jpg')\n",
    "cv2.imshow('IMAGE', img) # showing image on 'IMAGE' window\n",
    "cv2.waitKey(0)      # waits to press any key \n",
    "cv2.destroyAllWindows() # closing all open windows \n",
    "#plt.figure(figsize=(15, 15))\n",
    "#plt.imshow(img)\n",
    "#plt.title('IMAGE')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 1200, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width, _ = img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['person',\n",
       " 'bicycle',\n",
       " 'car',\n",
       " 'motorbike',\n",
       " 'aeroplane',\n",
       " 'bus',\n",
       " 'train',\n",
       " 'truck',\n",
       " 'boat',\n",
       " 'traffic light',\n",
       " 'fire hydrant',\n",
       " 'stop sign',\n",
       " 'parking meter',\n",
       " 'bench',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'dog',\n",
       " 'horse',\n",
       " 'sheep',\n",
       " 'cow',\n",
       " 'elephant',\n",
       " 'bear',\n",
       " 'zebra',\n",
       " 'giraffe',\n",
       " 'backpack',\n",
       " 'umbrella',\n",
       " 'handbag',\n",
       " 'tie',\n",
       " 'suitcase',\n",
       " 'frisbee',\n",
       " 'skis',\n",
       " 'snowboard',\n",
       " 'sports ball',\n",
       " 'kite',\n",
       " 'baseball bat',\n",
       " 'baseball glove',\n",
       " 'skateboard',\n",
       " 'surfboard',\n",
       " 'tennis racket',\n",
       " 'bottle',\n",
       " 'wine glass',\n",
       " 'cup',\n",
       " 'fork',\n",
       " 'knife',\n",
       " 'spoon',\n",
       " 'bowl',\n",
       " 'banana',\n",
       " 'apple',\n",
       " 'sandwich',\n",
       " 'orange',\n",
       " 'broccoli',\n",
       " 'carrot',\n",
       " 'hot dog',\n",
       " 'pizza',\n",
       " 'donut',\n",
       " 'cake',\n",
       " 'chair',\n",
       " 'sofa',\n",
       " 'pottedplant',\n",
       " 'bed',\n",
       " 'diningtable',\n",
       " 'toilet',\n",
       " 'tvmonitor',\n",
       " 'laptop',\n",
       " 'mouse',\n",
       " 'remote',\n",
       " 'keyboard',\n",
       " 'cell phone',\n",
       " 'microwave',\n",
       " 'oven',\n",
       " 'toaster',\n",
       " 'sink',\n",
       " 'refrigerator',\n",
       " 'book',\n",
       " 'clock',\n",
       " 'vase',\n",
       " 'scissors',\n",
       " 'teddy bear',\n",
       " 'hair drier',\n",
       " 'toothbrush']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Reading yolov3 pre-trained weights\n",
    "\n",
    "net = cv2.dnn.readNet('yolov3.weights', 'yolov3.cfg') \n",
    "\n",
    "# getting all 80 class names from coco.names file\n",
    "classes = []\n",
    "with open('coco.names', 'r') as f:\n",
    "      classes = f.read().splitlines()\n",
    "print(len(classes))   \n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   (416, 416)\n",
      "1   (416, 416)\n",
      "2   (416, 416)\n"
     ]
    }
   ],
   "source": [
    "## getting blob image of 'img'; cv2.dnn.blobFromImage function returns a blob which is our input image after \n",
    "## mean subtraction, normalizing, and channel swapping\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(img, 1/225, (416, 416), (0, 0, 0), swapRB=True, crop=False)\n",
    "for b in blob:\n",
    "    for n, img_blob in enumerate(b):\n",
    "        print(n,' ', img_blob.shape)\n",
    "        cv2.imshow(str(n), img_blob)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## feeding blob image into network\n",
    "\n",
    "net.setInput(blob)\n",
    "output_layers_names = net.getUnconnectedOutLayersNames() # Returns names of layers with unconnected outputs\n",
    "layerOutputs = net.forward(output_layers_names) # forward() - Runs a forward pass to compute the net output. i.e will give\n",
    "# Numpy ndarray as output which you can use it to plot box on the given input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yolo_82', 'yolo_94', 'yolo_106']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_layers_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(layerOutputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## start to get all required cordinates, class, confidences of predicted classes\n",
    "\n",
    "boxes = []\n",
    "confidences = []\n",
    "class_ids = []\n",
    "\n",
    "for output in layerOutputs:\n",
    "    #print('each outputlayer has', len(output), 'outputs')\n",
    "    for detection in output:\n",
    "        #print('each output has', len(detection), 'decection')\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > 0.5:\n",
    "            center_x = int(detection[0]*width)\n",
    "            center_y = int(detection[1]*height)\n",
    "            w = int(detection[2]*width)\n",
    "            h = int(detection[3]*height)\n",
    "\n",
    "            x = int(center_x - w/2)\n",
    "            y = int(center_y - h/2)\n",
    "\n",
    "            boxes.append([x, y, w, h])\n",
    "            confidences.append((float(confidence)))\n",
    "            class_ids.append(class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "25\n",
      "[2, 2, 3, 3, 7, 7, 7, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0]\n",
      "[0.7869579792022705, 0.768101155757904, 0.976364254951477, 0.8574442863464355, 0.5770198106765747, 0.7667111754417419, 0.7915807366371155, 0.7881016731262207, 0.8498850464820862, 0.826312780380249, 0.8652386665344238, 0.9609807133674622, 0.7774482369422913, 0.9725245833396912, 0.8578454256057739, 0.5049381256103516, 0.6707596778869629, 0.6279140710830688, 0.646953284740448, 0.8589062094688416, 0.5109004974365234, 0.7580952644348145, 0.814677357673645, 0.6933577656745911, 0.5432136654853821]\n"
     ]
    }
   ],
   "source": [
    "print(len(boxes))\n",
    "print(len(class_ids))\n",
    "print(class_ids)\n",
    "print(confidences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 2, 13, 11, 10, 14,  3,  8, 12,  1, 16, 18, 24], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## using NonMaxSupperssion to eliminate redundent bounding boxes on a single class based on maximum confidence.\n",
    "\n",
    "indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "print(len(indexes))\n",
    "indexes.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting bounding boxes, confidence and labels on images\n",
    "\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "colors = np.random.uniform(0, 255, size=(len(boxes), 3))\n",
    "\n",
    "for i in indexes.flatten():\n",
    "    x, y, w, h = boxes[i]\n",
    "    label = str(classes[class_ids[i]])\n",
    "    confidence = str(round(confidences[i], 2))\n",
    "    color = colors[i]\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), color, 2)\n",
    "    cv2.putText(img, label + ' ' + confidence, (x, y+20), font, 2, (255, 255, 255), 2)\n",
    "    \n",
    "cv2.imshow('Image', img)\n",
    "key = cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting thogether all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1zfvzLQtYSriv_HUKj623V8VYKZ2Tb2-p"
    },
    "executionInfo": {
     "elapsed": 13719,
     "status": "error",
     "timestamp": 1648044631900,
     "user": {
      "displayName": "lukman",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgYWpdLEDBgd-A_noCt6O-q-oYOLk5CEobYugF7pw=s64",
      "userId": "07982345385280399353"
     },
     "user_tz": -330
    },
    "id": "leO4hyKr375L",
    "outputId": "bb6c1eb2-e62f-405e-dc0a-61c924413c99"
   },
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNet('yolov3.weights', 'yolov3.cfg')\n",
    "\n",
    "classes = []\n",
    "with open('coco.names', 'r') as f:\n",
    "      classes = f.read().splitlines()\n",
    "\n",
    "img = cv2.imread('image3.jpg')\n",
    "height, width, _ = img.shape\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), (0, 0, 0), swapRB=True, crop=False)\n",
    "net.setInput(blob)\n",
    "output_layers_names = net.getUnconnectedOutLayersNames()\n",
    "layerOutputs = net.forward(output_layers_names)\n",
    "\n",
    "boxes = []\n",
    "confidences = []\n",
    "class_ids = []\n",
    "\n",
    "for output in layerOutputs:\n",
    "    for detection in output:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > 0.5:\n",
    "            center_x = int(detection[0]*width)\n",
    "            center_y = int(detection[1]*height)\n",
    "            w = int(detection[2]*width)\n",
    "            h = int(detection[3]*height)\n",
    "\n",
    "            x = int(center_x - w/2)\n",
    "            y = int(center_y - h/2)\n",
    "\n",
    "            boxes.append([x, y, w, h])\n",
    "            confidences.append((float(confidence)))\n",
    "            class_ids.append(class_id)\n",
    "\n",
    "indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "# plotting\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "colors = np.random.uniform(0, 255, size=(len(boxes), 3))\n",
    "\n",
    "for i in indexes.flatten():\n",
    "    x, y, w, h = boxes[i]\n",
    "    label = str(classes[class_ids[i]])\n",
    "    confidence = str(round(confidences[i], 2))\n",
    "    color = colors[i]\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), color, 1)\n",
    "    cv2.putText(img, label + ' ' + confidence, (x, y+20), font, 1, (255, 255, 255), 2)\n",
    "\n",
    "cv2.imshow('Image', img)\n",
    "key = cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "COtcFqZ5G-Fa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN2sQ8MO1VWSqg6q3mSObM9",
   "collapsed_sections": [],
   "mount_file_id": "1PD7O_tUrcN4scSgEhCGYy3R7kv5ZH3-G",
   "name": "video-object-detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
